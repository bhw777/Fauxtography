{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Colorspace EfficientNet (MC-EffNet)\n",
    "> Reference: [Distinguishing Natural and Computer-Generated Images using Multi-Colorspace fused EfficientNet](https://arxiv.org/pdf/2110.09428.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10\n",
    "BS = 32\n",
    "LR = 1e-4\n",
    "NUM_CLASSES = 2\n",
    "MODEL = 'efficientnet-b0'\n",
    "LEAST_NUM_TRAIN_DATA = 6000\n",
    "LEAST_NUM_VAL_DATA = 6000\n",
    "INPUT_IMG_SIZE = (128, 128)\n",
    "\n",
    "# ----- Original Fake2M dataset config-----\n",
    "mdl_pth = f'./model/efficientnet_model_SC_Fake2M.pth'\n",
    "rst_pth = f'./model/efficientnet_rst_SC_Fake2M.pth'\n",
    "train_data_pth = './Fake2M/train/'\n",
    "val_data_pth = './Fake2M/val/'\n",
    "\n",
    "# ----- Random compressed and cropped Fake2M dataset config-----\n",
    "# mdl_pth = f'./model/efficientnet_model_SC_Fake2M_cc.pth'\n",
    "# rst_pth = f'./model/efficientnet_rst_SC_Fake2M_cc.pth'\n",
    "# train_data_pth = './Fake2M_cc/train/'\n",
    "# val_data_pth = './Fake2M_cc/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(INPUT_IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=train_data_pth, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_data_pth, transform=transform)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(range(0, len(train_dataset), len(train_dataset) // LEAST_NUM_TRAIN_DATA)) \n",
    "val_sampler = SubsetRandomSampler(range(0, len(val_dataset), len(val_dataset) // LEAST_NUM_VAL_DATA))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BS, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 6944\n",
      "Number of validation data: 6784\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training data: {len(train_dataloader) * train_dataloader.batch_size}')\n",
    "print(f'Number of validation data: {len(val_dataloader) * val_dataloader.batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of data in each class\n",
    "check_data_label = False\n",
    "if check_data_label:\n",
    "    train_lbl_0 = 0\n",
    "    train_lbl_1 = 0\n",
    "    for _, labels in tqdm(train_dataloader):\n",
    "        train_lbl_0 += torch.count_nonzero(1-labels)\n",
    "        train_lbl_1 += torch.count_nonzero(labels)\n",
    "        \n",
    "    print(f'Number of label 0 (fake) training images: {train_lbl_0}')\n",
    "    print(f'Number of label 1 (real) training images: {train_lbl_1}')\n",
    "\n",
    "    val_lbl_0 = 0\n",
    "    val_lbl_1 = 0\n",
    "    for _, labels in tqdm(val_dataloader):\n",
    "        val_lbl_0 += torch.count_nonzero(1-labels)\n",
    "        val_lbl_1 += torch.count_nonzero(labels)\n",
    "        \n",
    "    print(f'Number of label 0 (fake) validation images: {val_lbl_0}')\n",
    "    print(f'Number of label 1 (real) validation images: {val_lbl_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "New Model created...\n",
      "No history result...\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(MODEL, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "if os.path.exists(mdl_pth):\n",
    "    checkpoint = torch.load(mdl_pth)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(\"Trained Model loaded...\")\n",
    "else:\n",
    "    print(\"New Model created...\")\n",
    "    \n",
    "if os.path.exists(rst_pth):\n",
    "    checkpoint = torch.load(rst_pth)\n",
    "    epoch_train_loss = checkpoint['epoch_training_loss']\n",
    "    epoch_train_accuracy = checkpoint['epoch_training_accuracy']\n",
    "    epoch_train_precision = checkpoint['epoch_training_precision']\n",
    "    epoch_train_recall = checkpoint['epoch_train_recall']\n",
    "    epoch_val_loss = checkpoint['epoch_val_loss']\n",
    "    epoch_val_accuracy = checkpoint['epoch_val_accuracy']\n",
    "    epoch_val_precision = checkpoint['epoch_val_precision']\n",
    "    epoch_val_recall = checkpoint['epoch_val_recall']\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    corres_val_precision = checkpoint['corres_val_precision']\n",
    "    corres_val_recall = checkpoint['corres_val_recall']\n",
    "    print(\"History result loaded...\")\n",
    "    print('Best model:')\n",
    "    print(f'Accuracy = {best_val_acc:.4f}')\n",
    "    print(f'Precision = {corres_val_precision:.4f}')\n",
    "    print(f'Recall = {corres_val_recall:.4f}')\n",
    "else:\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_accuracy = []\n",
    "    epoch_train_precision = []\n",
    "    epoch_train_recall = []\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_accuracy = []\n",
    "    epoch_val_precision = []\n",
    "    epoch_val_recall = []\n",
    "    best_val_acc = 0.0 \n",
    "    corres_val_precision = 0.0\n",
    "    corres_val_recall = 0.0\n",
    "    print(\"No history result...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:30<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Trn loss: 0.5986\n",
      "Trn accuracy: 0.7388\n",
      "Trn precision: 0.7415\n",
      "Trn recall: 0.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:24<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0157\n",
      "Val accuracy: 0.6950\n",
      "Val precision: 0.7682\n",
      "val recall: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:27<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n",
      "Trn loss: 0.7123\n",
      "Trn accuracy: 0.8737\n",
      "Trn precision: 0.8739\n",
      "Trn recall: 0.8654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:22<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3210\n",
      "Val accuracy: 0.7797\n",
      "Val precision: 0.7994\n",
      "val recall: 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:28<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n",
      "Trn loss: 0.4956\n",
      "Trn accuracy: 0.9278\n",
      "Trn precision: 0.9279\n",
      "Trn recall: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:23<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0007\n",
      "Val accuracy: 0.7930\n",
      "Val precision: 0.7981\n",
      "val recall: 0.8579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:33<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]\n",
      "Trn loss: 0.8810\n",
      "Trn accuracy: 0.9592\n",
      "Trn precision: 0.9592\n",
      "Trn recall: 0.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:23<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0394\n",
      "Val accuracy: 0.7828\n",
      "Val precision: 0.7930\n",
      "val recall: 0.8754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]\n",
      "Trn loss: 0.8173\n",
      "Trn accuracy: 0.9725\n",
      "Trn precision: 0.9725\n",
      "Trn recall: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:20<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0396\n",
      "Val accuracy: 0.7733\n",
      "Val precision: 0.7991\n",
      "val recall: 0.9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:32<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]\n",
      "Trn loss: 0.6217\n",
      "Trn accuracy: 0.9842\n",
      "Trn precision: 0.9842\n",
      "Trn recall: 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:23<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.1209\n",
      "Val accuracy: 0.7908\n",
      "Val precision: 0.8046\n",
      "val recall: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:27<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]\n",
      "Trn loss: 0.6830\n",
      "Trn accuracy: 0.9842\n",
      "Trn precision: 0.9842\n",
      "Trn recall: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:21<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0291\n",
      "Val accuracy: 0.7831\n",
      "Val precision: 0.7964\n",
      "val recall: 0.8884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:29<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]\n",
      "Trn loss: 0.8723\n",
      "Trn accuracy: 0.9900\n",
      "Trn precision: 0.9900\n",
      "Trn recall: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:22<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112\n",
      "Val accuracy: 0.7995\n",
      "Val precision: 0.8085\n",
      "val recall: 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:37<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]\n",
      "Trn loss: 1.2859\n",
      "Trn accuracy: 0.9883\n",
      "Trn precision: 0.9883\n",
      "Trn recall: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:27<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 2.7068\n",
      "Val accuracy: 0.7844\n",
      "Val precision: 0.7886\n",
      "val recall: 0.8436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:33<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]\n",
      "Trn loss: 0.6636\n",
      "Trn accuracy: 0.9894\n",
      "Trn precision: 0.9894\n",
      "Trn recall: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [01:23<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0006\n",
      "Val accuracy: 0.7903\n",
      "Val precision: 0.8031\n",
      "val recall: 0.8923\n",
      "=========================================================\n",
      "Best model: Accuracy = 0.7995, Precision = 0.8085, Recall = 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    # ====================== train ===========================\n",
    "    train_all_labels = []\n",
    "    train_all_preds = []\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        train_loss = criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_all_labels.extend(labels.cpu().numpy())\n",
    "        train_all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    train_accuracy = accuracy_score(train_all_labels, train_all_preds)\n",
    "    train_precision = precision_score(train_all_labels, train_all_preds, average='weighted')\n",
    "    train_recall = recall_score(train_all_labels, train_all_preds)\n",
    "    \n",
    "    epoch_train_loss += [train_loss.item()]\n",
    "    epoch_train_accuracy += [train_accuracy]\n",
    "    epoch_train_precision += [train_precision]\n",
    "    epoch_train_recall += [train_recall]\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCH}]')\n",
    "    print(f'Trn loss: {train_loss:.4f}')\n",
    "    print(f'Trn accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Trn precision: {train_precision:.4f}')\n",
    "    print(f'Trn recall: {train_recall:.4f}')\n",
    "    \n",
    "    # ======================= val ============================\n",
    "    model.eval()\n",
    "    val_all_labels = []\n",
    "    val_all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_all_labels.extend(labels.cpu().numpy())\n",
    "            val_all_preds.extend(preds.cpu().numpy())\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            \n",
    "    val_accuracy = accuracy_score(val_all_labels, val_all_preds)\n",
    "    val_precision = precision_score(val_all_labels, val_all_preds, average='weighted')\n",
    "    val_recall = recall_score(val_all_labels, val_all_preds)\n",
    "    \n",
    "    epoch_val_loss += [val_loss.item()]\n",
    "    epoch_val_accuracy += [val_accuracy]\n",
    "    epoch_val_precision += [val_precision]\n",
    "    epoch_val_recall += [val_recall]\n",
    "    \n",
    "    print(f'Val loss: {val_loss:.4f}')\n",
    "    print(f'Val accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Val precision: {val_precision:.4f}')\n",
    "    print(f'val recall: {val_recall:.4f}')\n",
    "        \n",
    "    if best_val_acc < val_accuracy:\n",
    "        best_val_acc = val_accuracy\n",
    "        corres_val_precision = val_precision\n",
    "        corres_val_recall = val_recall\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, mdl_pth)\n",
    "        \n",
    "    torch.save({\n",
    "        'epoch_training_loss': epoch_train_loss,\n",
    "        'epoch_training_accuracy': epoch_train_accuracy,\n",
    "        'epoch_training_precision': epoch_train_precision,\n",
    "        'epoch_train_recall': epoch_train_recall,\n",
    "        'epoch_val_loss': epoch_val_loss,\n",
    "        'epoch_val_accuracy': epoch_val_accuracy,\n",
    "        'epoch_val_precision': epoch_val_precision,\n",
    "        'epoch_val_recall': epoch_val_recall,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'corres_val_precision': corres_val_precision,\n",
    "        'corres_val_recall': corres_val_recall\n",
    "    }, rst_pth)\n",
    "        \n",
    "print(\"=========================================================\")\n",
    "print(f'Best model: Accuracy = {best_val_acc:.4f}, Precision = {corres_val_precision:.4f}, Recall = {corres_val_recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
